# CoE-197Z-Deep-Learning-Object-Detection


--
## Evaluation after model traning
Test:  [ 0/51]  eta: 0:00:02  model_time: 0.0299 (0.0299)  evaluator_time: 0.0030 (0.0030)  time: 0.0449  data: 0.0100  max mem: 465  
Test:  [50/51]  eta: 0:00:00  model_time: 0.0332 (0.0352)  evaluator_time: 0.0010 (0.0016)  time: 0.0482  data: 0.0104  max mem: 465  
Test: Total time: 0:00:02 (0.0484 s / it)  
Averaged stats: model_time: 0.0332 (0.0352)  evaluator_time: 0.0010 (0.0016)  
Accumulating evaluation results...  
DONE (t=0.02s).  
IoU metric: bbox  
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.820  
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.981  
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.922  
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000  
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.769  
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.824  
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.791  
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.854  
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.854  
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000  
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.775  
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.857  
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.857  
